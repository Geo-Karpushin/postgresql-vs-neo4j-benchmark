# Dataset Manager for Database Benchmarking

Менеджер датасетов для автоматизированного тестирования производительности баз данных PostgreSQL и Neo4j на различных размерах данных.

## Описание

Проект предоставляет инструмент для автоматического:
- Генерации датасетов социального графа (пользователи и дружеские связи)
- Загрузки данных в PostgreSQL и Neo4j
- Запуска бенчмарков с различными типами запросов
- Сбора и анализа результатов производительности

## Конфигурация датасетов

Поддерживаются следующие размеры датасетов:

| Размер | Пользователи | Среднее друзей | Итерации |
|--------|--------------|----------------|----------|
| super-tiny | 5,000 | 25 | 5 |
| tiny | 10,000 | 22 | 5 |
| very-small | 20,000 | 20 | 5 |
| small | 50,000 | 20 | 5 |
| medium | 500,000 | 18 | 3 |
| large | 2,000,000 | 15 | 2 |
| x-large | 5,000,000 | 12 | 1 |
| xx-large | 10,000,000 | 10 | 1 |

## Структура проекта

```
project/
├── scripts/               # Вспомогательные скрипты
│   ├── dataset_manager.py        # Главный скрипт менеджера датасетов
│   ├── init_database.py          # Инициализация схем БД
│   ├── cleanup_databases.py      # Очистка баз данных
│   ├── data_generator.py         # Генератор данных
│   ├── load_data.py              # Загрузка данных в БД
│   ├── benchmark_runner.py       # Запуск бенчмарков
│   └── inspect_databases.py      # Проверка данных в БД
├── generated/             # Сгенерированные датасеты
├── results/               # Результаты тестирования
├── charts/                # Графики с результатами
├── requirements/
│   └── requirements.txt   # Список необходимых бибилиотек для работы python
└── README.md
```

## Требования

- Python 3.7+
- Docker
- Docker Compose
- PostgreSQL (в контейнере)
- Neo4j (в контейнере)

## Установка и настройка

1. Убедитесь, что установлены Docker и Docker Compose
2. Запустите базы данных:
   ```bash
   docker-compose up -d
   ```
3. Установите зависимости Python (если есть requirements.txt)

## Использование

### Запуск всех тестов

```bash
python dataset_manager.py all
```

### Запуск конкретного размера датасета

```bash
python dataset_manager.py small
python dataset_manager.py medium
python dataset_manager.py large
```

### Пробный запуск (без выполнения команд)

```bash
python dataset_manager.py small --dry-run
```

## Процесс выполнения

Для каждого размера датасета выполняется:

1. **Очистка БД** - подготовка чистого состояния
2. **Инициализация схем** - создание таблиц/индексов
3. **Генерация данных** - создание CSV файлов с пользователями и связями
4. **Копирование в контейнеры** - перенос данных в Docker-контейнеры
5. **Загрузка в БД** - импорт данных в PostgreSQL и Neo4j
6. **Проверка данных** - верификация загруженных датасетов
7. **Запуск бенчмарков** - выполнение тестовых запросов
8. **Очистка** - подготовка к следующей итерации

## Типы запросов в бенчмарках

- **simple_friends** - простой запрос друзей пользователя
- **friends_of_friends** - друзья друзей (2 уровня)
- **mutual_friends** - общие друзья между двумя пользователями
- **friend_recommendations** - рекомендации друзей
- **shortest_path** - поиск кратчайшего пути между пользователями

## Результаты

Результаты сохраняются в папке `results/` в формате JSON для каждого размера датасета. Файлы содержат:

- Временные метки выполнения этапов
- Длительность каждого этапа
- Статус выполнения
- Конфигурацию датасета

## Особенности

- **Автоматические повторные попытки** для Docker-команд при ошибках
- **Гибкая конфигурация** количества запусков запросов для разных размеров
- **Многократные итерации** для повышения достоверности результатов
- **Поддержка больших датасетов** до 10 миллионов пользователей
- **Логирование** всех этапов выполнения

## Примечания

- Для работы скрипта должны быть запущены Docker-контейнеры с именами:
  - `database-benchmark-postgres-1`
  - `database-benchmark-neo4j-1`
- Убедитесь, что есть достаточно места на диске для больших датасетов
- Время выполнения зависит от размера датасета и производительности системы
